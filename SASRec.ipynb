{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1d1d5gAd4HIfuKNldgkro1mGYyJFkNeMi",
      "authorship_tag": "ABX9TyN/qwFX4x6m0/79wt7OBnqX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinpu/Recommendation-algorithm/blob/main/SASRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQKJuAClxVtY"
      },
      "source": [
        "## 数据处理函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0qP0l3qw8Hm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "def sparseFeature(feat, feat_num, embed_dim=4):\n",
        "    \"\"\"\n",
        "    create dictionary for sparse feature\n",
        "    :param feat: feature name\n",
        "    :param feat_num: the total number of sparse features that do not repeat\n",
        "    :param embed_dim: embedding dimension\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    return {'feat': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}\n",
        "\n",
        "\n",
        "def create_ml_1m_dataset(file, trans_score=2, embed_dim=8, maxlen=40, test_neg_num=100):\n",
        "    \"\"\"\n",
        "    :param file: A string. dataset path.\n",
        "    :param trans_score: A scalar. Greater than it is 1, and less than it is 0.\n",
        "    :param embed_dim: A scalar. latent factor.\n",
        "    :param maxlen: A scalar. maxlen.\n",
        "    :param test_neg_num: A scalar. The number of test negative samples\n",
        "    :return: user_num, item_num, train_df, test_df\n",
        "    \"\"\"\n",
        "    print('==========Data Preprocess Start=============')\n",
        "    data_df = pd.read_csv(file, sep=\"::\", engine='python',\n",
        "                          names=['user_id', 'item_id', 'label', 'Timestamp'])\n",
        "    # filtering\n",
        "    data_df['item_count'] = data_df.groupby('item_id')['item_id'].transform('count')\n",
        "    data_df = data_df[data_df.item_count >= 5]\n",
        "    # trans score\n",
        "    data_df = data_df[data_df.label >= trans_score]\n",
        "    # sort\n",
        "    data_df = data_df.sort_values(by=['user_id', 'Timestamp'])\n",
        "    # split dataset and negative sampling\n",
        "    print('============Negative Sampling===============')\n",
        "    train_data, val_data, test_data = defaultdict(list), defaultdict(list), defaultdict(list)\n",
        "    item_id_max = data_df['item_id'].max()\n",
        "    for user_id, df in tqdm(data_df[['user_id', 'item_id']].groupby('user_id')):\n",
        "        pos_list = df['item_id'].tolist()\n",
        "\n",
        "        def gen_neg():\n",
        "            neg = pos_list[0]\n",
        "            while neg in set(pos_list):\n",
        "                neg = random.randint(1, item_id_max)\n",
        "                return neg\n",
        "\n",
        "        neg_list = [gen_neg() for i in range(len(pos_list) + test_neg_num)]\n",
        "        for i in range(1, len(pos_list)):\n",
        "            hist_i = pos_list[:i]\n",
        "            if i == len(pos_list) - 1:\n",
        "                test_data['hist'].append(hist_i)\n",
        "                test_data['pos_id'].append(pos_list[i])\n",
        "                test_data['neg_id'].append(neg_list[i:])\n",
        "            elif i == len(pos_list) - 2:\n",
        "                val_data['hist'].append(hist_i)\n",
        "                val_data['pos_id'].append(pos_list[i])\n",
        "                val_data['neg_id'].append(neg_list[i])\n",
        "            else:\n",
        "                train_data['hist'].append(hist_i)\n",
        "                train_data['pos_id'].append(pos_list[i])\n",
        "                train_data['neg_id'].append(neg_list[i])\n",
        "    # item feature columns\n",
        "    user_num, item_num = data_df['user_id'].max() + 1, data_df['item_id'].max() + 1\n",
        "    item_feat_col = sparseFeature('item_id', item_num, embed_dim)\n",
        "    # shuffle\n",
        "    random.shuffle(train_data)\n",
        "    random.shuffle(val_data)\n",
        "    # padding\n",
        "    print('==================Padding===================')\n",
        "    train = [pad_sequences(train_data['hist'], maxlen=maxlen), np.array(train_data['pos_id']),\n",
        "               np.array(train_data['neg_id'])]\n",
        "    val = [pad_sequences(val_data['hist'], maxlen=maxlen), np.array(val_data['pos_id']),\n",
        "             np.array(val_data['neg_id'])]\n",
        "    test = [pad_sequences(test_data['hist'], maxlen=maxlen), np.array(test_data['pos_id']),\n",
        "             np.array(test_data['neg_id'])]\n",
        "    print('============Data Preprocess End=============')\n",
        "    return item_feat_col, train, val, test"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH6vKORUxUrT",
        "outputId": "c35b2235-727a-40ee-f1de-b93fb0b30b5e"
      },
      "source": [
        "file = '/content/drive/MyDrive/RecSysLab/SASRec/ml-1m/ratings.dat'\n",
        "trans_score = 1\n",
        "maxlen = 200\n",
        "test_neg_num = 100\n",
        "embed_dim = 50\n",
        "\n",
        "item_fea_col, train, val, test = create_ml_1m_dataset(file, trans_score, embed_dim, maxlen, test_neg_num)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========Data Preprocess Start=============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 35/6040 [00:00<00:17, 343.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "============Negative Sampling===============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6040/6040 [00:29<00:00, 202.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================Padding===================\n",
            "============Data Preprocess End=============\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QjCTvCI5wRK",
        "outputId": "127aa977-08f4-407b-d587-fa874b74a2a4"
      },
      "source": [
        "train[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    0, 3186],\n",
              "       [   0,    0,    0, ...,    0, 3186, 1270],\n",
              "       [   0,    0,    0, ..., 3186, 1270, 1721],\n",
              "       ...,\n",
              "       [3449, 2301, 1127, ...,  457, 3671,  232],\n",
              "       [2301, 1127,  592, ..., 3671,  232, 2917],\n",
              "       [1127,  592, 2407, ...,  232, 2917, 1921]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV98sNo0zxun"
      },
      "source": [
        "## 模型构建"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9o5P3Puz2d8"
      },
      "source": [
        "\n",
        "\n",
        "![image-20210411152238353](https://gitee.com/hello_yinpu/picture/raw/master/imgs/image-20210411152238353.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sroz0A3XyVT0"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Embedding, Conv1D"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0XTqff8pQw"
      },
      "source": [
        "class FFN(Layer):\n",
        "    def __init__(self, hidden_unit, d_model):\n",
        "        \"\"\"\n",
        "        Feed Forward Network\n",
        "        :param hidden_unit: A scalar. W1\n",
        "        :param d_model: A scalar. W2\n",
        "        \"\"\"\n",
        "        super(FFN, self).__init__()\n",
        "        self.conv1 = Conv1D(filters=hidden_unit, kernel_size=1, activation='relu', use_bias=True)\n",
        "        self.conv2 = Conv1D(filters=d_model, kernel_size=1, activation=None, use_bias=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        output = self.conv2(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads=1, ffn_hidden_unit=128, dropout=0., norm_training=True, causality=True):\n",
        "        \"\"\"\n",
        "        Encoder Layer\n",
        "        :param d_model: A scalar. The self-attention hidden size.\n",
        "        :param num_heads: A scalar. Number of heads.\n",
        "        :param ffn_hidden_unit: A scalar. Number of hidden unit in FFN\n",
        "        :param dropout: A scalar. Number of dropout.\n",
        "        :param norm_training: Boolean. If True, using layer normalization, default True\n",
        "        :param causality: Boolean. If True, using causality, default True\n",
        "        \"\"\"\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads, d_model)\n",
        "        self.ffn = FFN(ffn_hidden_unit, d_model)\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6, trainable=norm_training)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6, trainable=norm_training)\n",
        "\n",
        "        self.dropout1 = Dropout(dropout)\n",
        "        self.dropout2 = Dropout(dropout)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, mask = inputs\n",
        "\n",
        "        attention_mask = tf.py_function(generate_attention_mask, [mask], tf.bool)\n",
        "        attention_mask = tf.reshape(attention_mask, (-1,mask.shape[1], mask.shape[1]))\n",
        "        att_out = self.mha(x, x, attention_mask=attention_mask)  # （None, seq_len, d_model)\n",
        "\n",
        "        att_out = self.dropout1(att_out)\n",
        "        # residual add\n",
        "        out1 = self.layernorm1(x + att_out)\n",
        "        # ffn\n",
        "        ffn_out = self.ffn(out1)\n",
        "        ffn_out = self.dropout2(ffn_out)\n",
        "        # residual add\n",
        "        out2 = self.layernorm2(out1 + ffn_out)  # (None, seq_len, d_model)\n",
        "        return out2"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD0Ww9AqOFMX"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Embedding, Input\n",
        "\n",
        "\n",
        "class SASRec(tf.keras.Model):\n",
        "    def __init__(self, item_fea_col, blocks=1, num_heads=1, ffn_hidden_unit=128,\n",
        "                 dropout=0., maxlen=40, norm_training=True, causality=False, embed_reg=1e-6):\n",
        "        \"\"\"\n",
        "        SASRec model\n",
        "        :param item_fea_col: A dict contains 'feat_name', 'feat_num' and 'embed_dim'.\n",
        "        :param blocks: A scalar. The Number of blocks.\n",
        "        :param num_heads: A scalar. Number of heads.\n",
        "        :param ffn_hidden_unit: A scalar. Number of hidden unit in FFN\n",
        "        :param dropout: A scalar. Number of dropout.\n",
        "        :param maxlen: A scalar. Number of length of sequence\n",
        "        :param norm_training: Boolean. If True, using layer normalization, default True\n",
        "        :param causality: Boolean. If True, using causality, default True\n",
        "        :param embed_reg: A scalar. The regularizer of embedding\n",
        "        \"\"\"\n",
        "        super(SASRec, self).__init__()\n",
        "        # sequence length\n",
        "        self.maxlen = maxlen\n",
        "        # item feature columns\n",
        "        self.item_fea_col = item_fea_col\n",
        "        # embed_dim\n",
        "        self.embed_dim = self.item_fea_col['embed_dim']\n",
        "        # d_model must be the same as embedding_dim, because of residual connection\n",
        "        self.d_model = self.embed_dim\n",
        "        # item embedding\n",
        "        self.item_embedding = Embedding(input_dim=self.item_fea_col['feat_num'],\n",
        "                         input_length=1,\n",
        "                         output_dim=self.item_fea_col['embed_dim'],\n",
        "                         mask_zero=True,\n",
        "                         embeddings_initializer='random_uniform',\n",
        "                         embeddings_regularizer=l2(embed_reg))\n",
        "        self.pos_embedding = Embedding(input_dim=self.maxlen,\n",
        "                         input_length=1,\n",
        "                         output_dim=self.embed_dim,\n",
        "                         mask_zero=False,\n",
        "                         embeddings_initializer='random_uniform',\n",
        "                         embeddings_regularizer=l2(embed_reg))\n",
        "        self.dropout = Dropout(dropout)\n",
        "        # attention block\n",
        "        self.encoder_layer = [EncoderLayer(self.d_model, num_heads, ffn_hidden_unit,\n",
        "                           dropout, norm_training, causality) for b in range(blocks)]\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs\n",
        "        seq_inputs, pos_inputs, neg_inputs = inputs  # (None, maxlen), (None, 1), (None, 1)\n",
        "        # mask\n",
        "        mask = tf.expand_dims(tf.cast(tf.not_equal(seq_inputs, 0), dtype=tf.float32), axis=-1)  # (None, maxlen, 1)\n",
        "        # seq info\n",
        "        seq_embed = self.item_embedding(seq_inputs)  # (None, maxlen, dim)\n",
        "        # pos encoding\n",
        "        # pos_encoding = positional_encoding(seq_inputs, self.embed_dim)\n",
        "        pos_encoding = tf.expand_dims(self.pos_embedding(tf.range(self.maxlen)), axis=0)\n",
        "        seq_embed += pos_encoding\n",
        "        seq_embed = self.dropout(seq_embed)\n",
        "        att_outputs = seq_embed  # (None, maxlen, dim)\n",
        "        att_outputs *= mask\n",
        "\n",
        "        # self-attention\n",
        "        for block in self.encoder_layer:\n",
        "            att_outputs = block([att_outputs, mask])  # (None, seq_len, dim)\n",
        "            att_outputs *= mask\n",
        "\n",
        "        # user_info = tf.reduce_mean(att_outputs, axis=1)  # (None, dim)\n",
        "        user_info = tf.expand_dims(att_outputs[:, -1], axis=1)  # (None, 1, dim)\n",
        "        # item info\n",
        "        pos_info = self.item_embedding(pos_inputs)  # (None, 1, dim)\n",
        "        neg_info = self.item_embedding(neg_inputs)  # (None, 1/100, dim)\n",
        "        pos_logits = tf.reduce_sum(user_info * pos_info, axis=-1)  # (None, 1)\n",
        "        neg_logits = tf.reduce_sum(user_info * neg_info, axis=-1)  # (None, 1)\n",
        "        # loss\n",
        "        losses = tf.reduce_mean(- tf.math.log(tf.nn.sigmoid(pos_logits)) -\n",
        "                                tf.math.log(1 - tf.nn.sigmoid(neg_logits))) / 2\n",
        "        self.add_loss(losses)\n",
        "        logits = tf.concat([pos_logits, neg_logits], axis=-1)\n",
        "        return logits\n",
        "\n",
        "    def summary(self):\n",
        "        seq_inputs = Input(shape=(self.maxlen,), dtype=tf.int32)\n",
        "        pos_inputs = Input(shape=(1,), dtype=tf.int32)\n",
        "        neg_inputs = Input(shape=(1,), dtype=tf.int32)\n",
        "        tf.keras.Model(inputs=[seq_inputs, pos_inputs, neg_inputs],\n",
        "                       outputs=self.call([seq_inputs, pos_inputs, neg_inputs])).summary()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSBAWo2b9Hma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46535f79-e8e2-42a9-980d-9f23a9d4d330"
      },
      "source": [
        "\n",
        "trans_score = 1\n",
        "maxlen = 200\n",
        "test_neg_num = 100\n",
        "\n",
        "embed_dim = 50\n",
        "blocks = 2\n",
        "num_heads = 1\n",
        "ffn_hidden_unit = 64\n",
        "dropout = 0.2\n",
        "norm_training = True\n",
        "causality = False\n",
        "embed_reg = 0  # 1e-6\n",
        "K = 10\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 50\n",
        "batch_size = 512\n",
        "model = SASRec(item_fea_col, blocks, num_heads, ffn_hidden_unit, dropout,\n",
        "        maxlen, norm_training, causality, embed_reg)\n",
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        multiple             197650      input_13[0][0]                   \n",
            "                                                                 input_14[0][0]                   \n",
            "                                                                 input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.not_equal_4 (TFOpLambda (None, 200)          0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 200, 50)      0           embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_4 (TFOpLambda)          (None, 200)          0           tf.math.not_equal_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 200, 50)      0           tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.expand_dims_8 (TFOpLambda)   (None, 200, 1)       0           tf.cast_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_20 (TFOpLambda (None, 200, 50)      0           dropout_21[0][0]                 \n",
            "                                                                 tf.expand_dims_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "encoder_layer_9 (EncoderLayer)  (None, 200, 50)      16914       tf.math.multiply_20[0][0]        \n",
            "                                                                 tf.expand_dims_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_21 (TFOpLambda (None, 200, 50)      0           encoder_layer_9[0][0]            \n",
            "                                                                 tf.expand_dims_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "encoder_layer_10 (EncoderLayer) (None, 200, 50)      16914       tf.math.multiply_21[0][0]        \n",
            "                                                                 tf.expand_dims_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_22 (TFOpLambda (None, 200, 50)      0           encoder_layer_10[0][0]           \n",
            "                                                                 tf.expand_dims_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli (None, 50)           0           tf.math.multiply_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.expand_dims_9 (TFOpLambda)   (None, 1, 50)        0           tf.__operators__.getitem_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_23 (TFOpLambda (None, 1, 50)        0           tf.expand_dims_9[0][0]           \n",
            "                                                                 embedding_10[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_24 (TFOpLambda (None, 1, 50)        0           tf.expand_dims_9[0][0]           \n",
            "                                                                 embedding_10[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum_8 (TFOpLambd (None, 1)            0           tf.math.multiply_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum_9 (TFOpLambd (None, 1)            0           tf.math.multiply_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_4 (TFOpLambda)        (None, 2)            0           tf.math.reduce_sum_8[0][0]       \n",
            "                                                                 tf.math.reduce_sum_9[0][0]       \n",
            "==================================================================================================\n",
            "Total params: 231,478\n",
            "Trainable params: 231,478\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_YKBgVDdfYl"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KMUdvlSd2mo"
      },
      "source": [
        "def evaluate_model(model, test, K):\n",
        "    \"\"\"\n",
        "    evaluate model\n",
        "    :param model: model\n",
        "    :param test: test set\n",
        "    :param K: top K\n",
        "    :return: hit rate, ndcg\n",
        "    \"\"\"\n",
        "    pred_y = - model.predict(test)\n",
        "    rank = pred_y.argsort().argsort()[:, 0]\n",
        "    hr, ndcg = 0.0, 0.0\n",
        "    for r in rank:\n",
        "        if r < K:\n",
        "            hr += 1\n",
        "            ndcg += 1 / np.log2(r + 2)\n",
        "    return hr / len(rank), ndcg / len(rank)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD1A_GBEeEYO",
        "outputId": "6103df1d-8d21-4879-a654-70211b191483"
      },
      "source": [
        "results = []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # ===========================Fit==============================\n",
        "    t1 = time()\n",
        "    model.fit(\n",
        "        train,\n",
        "        validation_data=(val, None),\n",
        "        epochs=1,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    # ===========================Test==============================\n",
        "    t2 = time()\n",
        "    if epoch % 5 == 0:\n",
        "        hit_rate, ndcg = evaluate_model(model, test, K)\n",
        "        print('Iteration %d Fit [%.1f s], Evaluate [%.1f s]: HR = %.4f, NDCG = %.4f, '\n",
        "              % (epoch, t2 - t1, time() - t2, hit_rate, ndcg))\n",
        "        results.append([epoch + 1, t2 - t1, time() - t2, hit_rate, ndcg])\n",
        "# ============================Write============================\n",
        "pd.DataFrame(results, columns=['Iteration', 'fit_time', 'evaluate_time', 'hit_rate', 'ndcg']).\\\n",
        "    to_csv('log/SASRec_log_maxlen_{}_dim_{}_blocks_{}_heads_{}_K_{}_.csv'.\n",
        "            format(maxlen, embed_dim, blocks, num_heads, K), index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  56/1917 [..............................] - ETA: 2:00:42 - loss: 0.6746"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZJT90GcQuxA"
      },
      "source": [
        "def generate_attention_mask(mask):\n",
        "  # mask: (B,maxlen,1)\n",
        "  mask_ = mask.numpy()\n",
        "  attention_mask_list = np.array([np.eye(mask_.shape[1]) for _ in range(mask_.shape[0])])\n",
        "  for i in range(mask_.shape[0]):\n",
        "    mask_i = mask_[i,:,0] #(maxlen,)\n",
        "    first_true_pos = int(mask_i.shape[0]-np.sum(mask_i))\n",
        "    for j in range(mask_i.shape[0]) :\n",
        "      if j > first_true_pos :\n",
        "        attention_mask_list[i, j, first_true_pos:j] = 1\n",
        "  return attention_mask_list"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xR6223mSRNr",
        "outputId": "6f5f0760-3bf6-458d-f06e-855a0fe5520f"
      },
      "source": [
        "mask1 = [[False,False,True],[False,True,True],[True,True,True]]\n",
        "mask1 = tf.reshape(mask1, shape=(-1,3,1))\n",
        "mask1"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 1), dtype=bool, numpy=\n",
              "array([[[False],\n",
              "        [False],\n",
              "        [ True]],\n",
              "\n",
              "       [[False],\n",
              "        [ True],\n",
              "        [ True]],\n",
              "\n",
              "       [[ True],\n",
              "        [ True],\n",
              "        [ True]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA8fs2McSRMW",
        "outputId": "93962b03-c4b2-4258-9a7f-ff6dac87229f"
      },
      "source": [
        "generate_attention_mask(mask1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]],\n",
              "\n",
              "       [[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 1.]],\n",
              "\n",
              "       [[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aM5LXrHFeiM",
        "outputId": "72dfb298-c741-4695-db9d-5b5bcffa1bcf"
      },
      "source": [
        "\n",
        "def add_sub(x, y):\n",
        "    '''\n",
        "    在此函数中使用纯python编程方式\n",
        "    '''\n",
        "    x_ = x.numpy()\n",
        "    y_ = y.numpy()\n",
        "    result1 = x_ + y_ - (x_ - y_)\n",
        "    result2 = x_ + y_ + (x_ - y_)  \n",
        "    # 返回的就是普通的python对象，但是它会自动转化成tensor来作为最终的结果，是自动完成的\n",
        "    return result1,result2\n",
        " \n",
        "x = tf.constant([10,20,30])\n",
        "y = tf.constant([100,200,300])\n",
        " \n",
        "y1,y2 = tf.py_function(func=add_sub, inp=[x, y], Tout=[tf.int32,tf.int32])\n",
        "print(y1)  \n",
        "print(y2) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([200 400 600], shape=(3,), dtype=int32)\n",
            "tf.Tensor([20 40 60], shape=(3,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VP_ExZOMEgh"
      },
      "source": [
        "def stit(x):\n",
        "    '''\n",
        "    在此函数中使用纯python编程方式\n",
        "    '''\n",
        "    x_ = x.numpy()\n",
        "    x_[x_<0.1] = 0\n",
        "    x = np.concatenate((x,x),axis=1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cywiKMyBKqpW"
      },
      "source": [
        "def test_model(input_shape):\n",
        "  input_x = tf.keras.layers.Input(shape=(input_shape,))\n",
        "  tmp = tf.py_function(func=stit, inp=[input_x], Tout=tf.float32)\n",
        "  tmp = tf.reshape(tmp,(-1,7))\n",
        "  return tf.keras.models.Model(inputs=input_x, outputs=tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpH1wdQeOiqi"
      },
      "source": [
        "t_model = test_model(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIhMcjopOpm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f249d0-ea14-44a0-d5de-188221998c6e"
      },
      "source": [
        "t_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_25 (InputLayer)        [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "tf.py_function_22 (TFOpLambd None                      0         \n",
            "_________________________________________________________________\n",
            "tf.reshape_15 (TFOpLambda)   (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDN29R_EyflD"
      },
      "source": [
        "x=tf.constant([[0.1,-0.2,0.3,-10000000,0.5,0.6,0.7,0.8,-1000,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EutwUtM0bl9",
        "outputId": "b355989a-7967-45a4-d018-872c4666f42f"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "nVEpOd4o0uzg",
        "outputId": "e6677679-10c1-4231-f843-f835243d73e5"
      },
      "source": [
        "t_model(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-5e2e1609af7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# multiple ops w/ the same name when the layer is reused)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8371\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8372\u001b[0m       return reshape_eager_fallback(\n\u001b[0;32m-> 8373\u001b[0;31m           tensor, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   8374\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8375\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8396\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8397\u001b[0m   _result = _execute.execute(b\"Reshape\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 8398\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   8399\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8400\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 20 values, but the requested shape requires a multiple of 7 [Op:Reshape]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkKsM_Sk0xFQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}